from core.executor import execute_plan
from agent_local.llm_ollama import run_local_ai_reasoning
from agent_cloud.gemini_client import run_gemini_reasoning
from config.devices_config import USING_DEVICES
from logger.print_log import print_result, save_log_file

def run_ai_network_agent(mode="rule"):
    user_input = input("\nğŸ’¬ Nháº­p Ä‘á» bÃ i cáº¥u hÃ¬nh (hoáº·c 'exit'): ")
    if user_input.lower() == "exit":
        return

    if mode == "ollama":
        print("\nğŸ§  Äang phÃ¢n tÃ­ch Ä‘á» bÃ i báº±ng Mistral Local...")
        steps = run_local_ai_reasoning(user_input)
    elif mode == "gemini":
        print("\nğŸ§  Äang phÃ¢n tÃ­ch Ä‘á» bÃ i báº±ng Gemini AI...")
        steps = run_gemini_reasoning(user_input)
    else:
        print("\nâš™ï¸ PhÃ¢n tÃ­ch Ä‘á» bÃ i báº±ng rule cÆ¡ báº£n...")
        if "ospf" in user_input.lower():
            steps = ["cáº¥u hÃ¬nh ospf", "show ip ospf neighbor"]
        else:
            steps = ["ping 192.168.0.1"]

    print("\nğŸ“‹ Káº¿ hoáº¡ch hÃ nh Ä‘á»™ng:", steps)
    print("\nğŸ“¡ Báº¯t Ä‘áº§u thá»±c hiá»‡n cáº¥u hÃ¬nh...")

    logs = execute_plan(steps, USING_DEVICES)
    print_result(logs)
    save_log_file(logs)
