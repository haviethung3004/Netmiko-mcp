from agent_local.llm_ollama import run_local_ai_reasoning
from agent_local.llm_gemini import run_gemini_ai_reasoning
from agent_local.fallback_reasoner import fallback_reasoning
from config.devices_config import USING_DEVICES
from core.executor import execute_plan

def run_ai_network_agent(mode="ollama"):
    print(f"ğŸ¤– AI Network Engineer Agent (Cháº¿ Ä‘á»™: {mode})")

    while True:
        user_input = input("\nğŸ’¬ Nháº­p Ä‘á» bÃ i cáº¥u hÃ¬nh (hoáº·c 'exit'): ")
        if user_input.lower() == "exit":
            break

        print("\nğŸ§  Äang phÃ¢n tÃ­ch Ä‘á» bÃ i...")

        if mode == "ollama":
            plan = run_local_ai_reasoning(user_input)
        elif mode == "gemini":
            plan = run_gemini_ai_reasoning(user_input)
        else:
            plan = fallback_reasoning(user_input)

        print("\nğŸ“‹ Káº¿ hoáº¡ch:")
        for i, step in enumerate(plan, 1):
            print(f"  {i}. {step}")

        print("\nğŸ› ï¸ Thá»±c thi:")
        logs = execute_plan(plan, USING_DEVICES)

        for log in logs:
            print(log)